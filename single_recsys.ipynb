{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, accuracy\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0619\n",
      "MAE:  0.7493\n",
      "MRR@10: 0.8407\n",
      "NDCG@10: 0.8275\n",
      "HR@10: 0.8592\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "from surprise import accuracy\n",
    "import numpy as np\n",
    "\n",
    "# Define the file path\n",
    "data_path = 'musical_instruments_reviews'\n",
    "df_data = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# Drop the 'timestamp:float' column as it is not needed anymore\n",
    "df_data = df_data.drop(columns=['timestamp:float'])\n",
    "\n",
    "# Read data so that it fits the requirements of surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order)\n",
    "data = Dataset.load_from_df(df_data[['user_id:token', 'item_id:token', 'rating:float']], reader)\n",
    "\n",
    "# Test set is made of 25% of the ratings\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create an instance of the SVD algorithm\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Predict ratings for the testset\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Calculate RMSE and MAE\n",
    "accuracy.rmse(predictions)\n",
    "accuracy.mae(predictions)\n",
    "\n",
    "# Calculate MRR@10, NDCG@10, and HR@10\n",
    "def calculate_metrics_at_k(predictions, k=10):\n",
    "    user_est_true = {}\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        if uid not in user_est_true:\n",
    "            user_est_true[uid] = []\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    \n",
    "    mrr = 0\n",
    "    ndcg = 0\n",
    "    hr = 0\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        # Sort user ratings by estimated rating in descending order\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        user_ratings = user_ratings[:k]\n",
    "        \n",
    "        # Calculate MRR@10\n",
    "        for rank, (_, true_r) in enumerate(user_ratings, start=1):\n",
    "            if true_r >= 4:  # Assuming a relevant rating is 4 or higher\n",
    "                mrr += 1 / rank\n",
    "                break\n",
    "        \n",
    "        # Calculate NDCG@10\n",
    "        dcg = sum((true_r >= 4) / np.log2(rank + 1) for rank, (_, true_r) in enumerate(user_ratings, start=1))\n",
    "        idcg = sum(1 / np.log2(rank + 1) for rank in range(1, min(k, len(user_ratings)) + 1))\n",
    "        ndcg += dcg / idcg if idcg > 0 else 0\n",
    "        \n",
    "        # Calculate HR@10\n",
    "        hr += any(true_r >= 4 for _, true_r in user_ratings)\n",
    "    \n",
    "    mrr /= len(user_est_true)\n",
    "    ndcg /= len(user_est_true)\n",
    "    hr /= len(user_est_true)\n",
    "    \n",
    "    return mrr, ndcg, hr\n",
    "\n",
    "mrr, ndcg, hr = calculate_metrics_at_k(predictions, k=10)\n",
    "print(f'MRR@10: {mrr:.4f}')\n",
    "print(f'NDCG@10: {ndcg:.4f}')\n",
    "print(f'HR@10: {hr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0199  1.0588  1.0823  1.1232  1.0555  1.0679  0.0341  \n",
      "MAE (testset)     0.7163  0.7507  0.7600  0.7728  0.7356  0.7471  0.0196  \n",
      "Fit time          0.06    0.05    0.05    0.05    0.05    0.05    0.01    \n",
      "Test time         0.01    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "{'test_rmse': array([1.0199267 , 1.05875004, 1.08229234, 1.12317493, 1.05549585]), 'test_mae': array([0.71633223, 0.75072519, 0.75996365, 0.77282427, 0.7355886 ]), 'fit_time': (0.06410908699035645, 0.05234360694885254, 0.05190873146057129, 0.050002098083496094, 0.04785585403442383), 'test_time': (0.005278110504150391, 0.00433802604675293, 0.004034996032714844, 0.004123687744140625, 0.003971099853515625)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split, cross_validate\n",
    "\n",
    "# Define the file path\n",
    "data_path = 'musical_instruments_reviews'\n",
    "df_data = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# Drop the 'timestamp:float' column as it is not needed anymore\n",
    "df_data = df_data.drop(columns=['timestamp:float'])\n",
    "\n",
    "# Read data so that it fits the requirements of surprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order)\n",
    "data = Dataset.load_from_df(df_data[['user_id:token', 'item_id:token', 'rating:float']], reader)\n",
    "\n",
    "# Test set is made of 25% of the ratings\n",
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "\n",
    "# Create an instance of the SVD algorithm\n",
    "algo = SVD()\n",
    "\n",
    "# Perform cross-validation\n",
    "results = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)\n",
    "\n",
    "# Print the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'raw_ratings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sh/fjb1r_5j6gxcy4lzfcc4_4zr0000gn/T/ipykernel_54258/820467468.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp:float'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# test set is made of 25% of the ratings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# We'll use the famous SVD algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Master/3-Semester/research-project/.venv/lib/python3.11/site-packages/surprise/model_selection/split.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(data, test_size, train_size, random_state, shuffle)\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     )\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code/Master/3-Semester/research-project/.venv/lib/python3.11/site-packages/surprise/model_selection/split.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mtuple\u001b[0m \u001b[0mof\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         test_size, train_size = self.validate_train_test_sizes(\n\u001b[0;32m--> 289\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_ratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         )\n\u001b[1;32m    291\u001b[0m         \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/Master/3-Semester/research-project/.venv/lib/python3.11/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'raw_ratings'"
     ]
    }
   ],
   "source": [
    "data_path = 'musical_instruments_reviews'\n",
    "df_data = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# drop timestamp, rating_age, and rating_age_days columns as it is not needed anymore\n",
    "df_data = df_data.drop(columns=['timestamp:float'])\n",
    "\n",
    "\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(df_data, test_size=0.25)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# reader = Reader(line_format=\"user_id:token item_id:token timestamp:float rating:float\", sep=\"\\t\")\n",
    "\n",
    "# data = Dataset.load_from_file(file_path, reader=reader)\n",
    "# data = Dataset.load_from_file(data_path, reader=reader)\n",
    "\n",
    "# trainset, testset = train_test_split(df_training_svd, test_size=0.25)\n",
    "\n",
    "# read data so that it fits the requirements of suprise\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "trainset = Dataset.load_from_df(trainset[['user_id:token', 'item_id:token', 'rating:float']], reader).build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "algo = SVD()\n",
    "# algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Trainset' object has no attribute 'raw_ratings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRMSE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMAE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/Master/3-Semester/research-project/.venv/lib/python3.11/site-packages/surprise/model_selection/validation.py:108\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(algo, data, measures, cv, return_train_measures, n_jobs, pre_dispatch, verbose)\u001b[0m\n\u001b[1;32m    102\u001b[0m cv \u001b[38;5;241m=\u001b[39m get_cv(cv)\n\u001b[1;32m    104\u001b[0m delayed_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    105\u001b[0m     delayed(fit_and_score)(algo, trainset, testset, measures, return_train_measures)\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (trainset, testset) \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(data)\n\u001b[1;32m    107\u001b[0m )\n\u001b[0;32m--> 108\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mout)\n\u001b[1;32m    112\u001b[0m test_measures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n",
      "File \u001b[0;32m~/Code/Master/3-Semester/research-project/.venv/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Code/Master/3-Semester/research-project/.venv/lib/python3.11/site-packages/joblib/parallel.py:1844\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;66;03m# Sequentially call the tasks and yield the results.\u001b[39;00m\n\u001b[0;32m-> 1844\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_dispatched_batches\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   1846\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_dispatched_tasks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/Code/Master/3-Semester/research-project/.venv/lib/python3.11/site-packages/surprise/model_selection/validation.py:104\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    100\u001b[0m measures \u001b[38;5;241m=\u001b[39m [m\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m measures]\n\u001b[1;32m    102\u001b[0m cv \u001b[38;5;241m=\u001b[39m get_cv(cv)\n\u001b[0;32m--> 104\u001b[0m delayed_list \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43malgo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_train_measures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m out \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)(delayed_list)\n\u001b[1;32m    110\u001b[0m (test_measures_dicts, train_measures_dicts, fit_times, test_times) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mout)\n",
      "File \u001b[0;32m~/Code/Master/3-Semester/research-project/.venv/lib/python3.11/site-packages/surprise/model_selection/split.py:92\u001b[0m, in \u001b[0;36mKFold.split\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generator function to iterate over trainsets and testsets.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;124;03m        tuple of (trainset, testset)\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_ratings\u001b[49m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect value for n_splits=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust be >=2 and less than the number \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof ratings\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mraw_ratings))\n\u001b[1;32m     97\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# We use indices to avoid shuffling the original data.raw_ratings list.\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trainset' object has no attribute 'raw_ratings'"
     ]
    }
   ],
   "source": [
    "cross_validate(algo, trainset, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    1.0745  1.0872  1.0795  1.0464  1.0319  1.0639  0.0211  \n",
      "MAE (testset)     0.7501  0.7602  0.7527  0.7383  0.7204  0.7444  0.0139  \n",
      "Fit time          0.07    0.05    0.05    0.05    0.05    0.06    0.01    \n",
      "Test time         0.00    0.00    0.00    0.01    0.00    0.00    0.00    \n",
      "{'test_rmse': array([1.07445898, 1.08719934, 1.07952739, 1.04639543, 1.03187788]), 'test_mae': array([0.75008002, 0.76023609, 0.75274104, 0.73834708, 0.72041545]), 'fit_time': (0.06657624244689941, 0.051113128662109375, 0.05460309982299805, 0.05214500427246094, 0.052848100662231445), 'test_time': (0.004228830337524414, 0.00386810302734375, 0.003763914108276367, 0.0051081180572509766, 0.004650115966796875)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Define the file path\n",
    "data_path = 'musical_instruments_reviews'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df_training_svd = pd.read_csv(data_path, sep='\\t')\n",
    "\n",
    "# Drop the 'timestamp:float' column as it is not needed anymore\n",
    "df_training_svd = df_training_svd.drop(columns=['timestamp:float'])\n",
    "\n",
    "# Define the reader with the rating scale\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order)\n",
    "trainset = Dataset.load_from_df(df_training_svd[['user_id:token', 'item_id:token', 'rating:float']], reader)\n",
    "\n",
    "# Create an instance of the SVD algorithm\n",
    "algo = SVD()\n",
    "\n",
    "# Perform cross-validation\n",
    "results = cross_validate(algo, trainset, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)\n",
    "\n",
    "# Print the results\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
